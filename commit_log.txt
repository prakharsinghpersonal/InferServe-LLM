- Commit 2 (vLLM Backend Integration): Write the Triton model configuration (config.pbtxt) and Python backend scripts to utilize vLLM for model serving.
- Commit 3 (Asynchronous Routing): Configure Triton's dynamic batching and asynchronous request routing to handle demanding concurrent workloads.
- Commit 4 (Stress Testing): Build a Python client script to simulate high concurrent language inference requests and measure throughput/latency.
